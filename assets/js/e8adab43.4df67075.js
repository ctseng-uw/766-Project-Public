"use strict";(self.webpackChunkcs_766_website=self.webpackChunkcs_766_website||[]).push([[293],{3905:function(e,n,r){r.d(n,{Zo:function(){return u},kt:function(){return g}});var t=r(7294);function a(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function i(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function o(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?i(Object(r),!0).forEach((function(n){a(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function c(e,n){if(null==e)return{};var r,t,a=function(e,n){if(null==e)return{};var r,t,a={},i=Object.keys(e);for(t=0;t<i.length;t++)r=i[t],n.indexOf(r)>=0||(a[r]=e[r]);return a}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)r=i[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=t.createContext({}),l=function(e){var n=t.useContext(s),r=n;return e&&(r="function"==typeof e?e(n):o(o({},n),e)),r},u=function(e){var n=l(e.components);return t.createElement(s.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},f=t.forwardRef((function(e,n){var r=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,u=c(e,["components","mdxType","originalType","parentName"]),f=l(r),g=a,d=f["".concat(s,".").concat(g)]||f[g]||p[g]||i;return r?t.createElement(d,o(o({ref:n},u),{},{components:r})):t.createElement(d,o({ref:n},u))}));function g(e,n){var r=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var i=r.length,o=new Array(i);o[0]=f;var c={};for(var s in n)hasOwnProperty.call(n,s)&&(c[s]=n[s]);c.originalType=e,c.mdxType="string"==typeof e?e:a,o[1]=c;for(var l=2;l<i;l++)o[l]=r[l];return t.createElement.apply(null,o)}return t.createElement.apply(null,r)}f.displayName="MDXCreateElement"},7385:function(e,n,r){r.r(n),r.d(n,{assets:function(){return u},contentTitle:function(){return s},default:function(){return g},frontMatter:function(){return c},metadata:function(){return l},toc:function(){return p}});var t=r(7462),a=r(3366),i=(r(7294),r(3905)),o=["components"],c={},s="Reference",l={unversionedId:"reference",id:"reference",title:"Reference",description:"1. zi2zi: Master chinese calligraphy with conditional adversarial networks.",source:"@site/docs/9-reference.md",sourceDirName:".",slug:"/reference",permalink:"/766-Project-Public/docs/reference",tags:[],version:"current",sidebarPosition:9,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Video",permalink:"/766-Project-Public/docs/video"}},u={},p=[],f={toc:p};function g(e){var n=e.components,r=(0,a.Z)(e,o);return(0,i.kt)("wrapper",(0,t.Z)({},f,r,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"reference"},"Reference"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"zi2zi: Master chinese calligraphy with conditional adversarial networks."),(0,i.kt)("li",{parentName:"ol"},"Bo Chang, Qiong Zhang, Shenyi Pan, and Lili Meng. Generating handwritten chinese characters using cyclegan. In\n2018 IEEE winter conference on applications of computer vision (WACV), pages 199\u2013207. IEEE, 2018."),(0,i.kt)("li",{parentName:"ol"},"fendaq. cascaded-pix2pix\u2014chinese-handwriting-generator-, 11 2021."),(0,i.kt)("li",{parentName:"ol"},"Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial\nnetworks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1125\u20131134, 2017."),(0,i.kt)("li",{parentName:"ol"},"Yangchen Xie, Xinyuan Chen, Li Sun, and Yue Lu. Dg-font: Deformable generative networks for unsupervised font\ngeneration. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5130\u2013\n5140, 2021."),(0,i.kt)("li",{parentName:"ol"},"Songhua Xu, Tao Jin, Hao Jiang, and Francis CM Lau. Automatic generation of personal chinese handwriting by\ncapturing the characteristics of personal handwriting. In Twenty-First IAAI Conference, 2009."),(0,i.kt)("li",{parentName:"ol"},"Jinshan Zeng, Qi Chen, Yunxin Liu, Mingwen Wang, and Yuan Yao. Strokegan: Reducing mode collapse in chinese\nfont generation via stroke encoding. In proceedings of AAAI, volume 3, 2021."),(0,i.kt)("li",{parentName:"ol"},"Yexun Zhang, Ya Zhang, and Wenbin Cai. Separating style and content for generalized style transfer. In Proceedings\nof the IEEE conference on computer vision and pattern recognition, pages 8447\u20138455, 2018."),(0,i.kt)("li",{parentName:"ol"},"Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle consistent adversarial networks. In Proceedings of the IEEE international conference on computer vision, pages 2223\u20132232, 2017"),(0,i.kt)("li",{parentName:"ol"},"Aaron Gokaslan, Vivek Ramanujan, Daniel Ritchie, Kwang In Kim, and James Tompkin.\nImproving shape deformation in unsupervised image-to-image translation. In Vittorio Ferrari,\nMartial Hebert, Cristian Sminchisescu, and Yair Weiss, editors, Computer Vision - ECCV 2018 -\n15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part XII,\nvolume 11216 of Lecture Notes in Computer Science, pages 662\u2013678. Springer, 2018."),(0,i.kt)("li",{parentName:"ol"},"Ming-Yu Liu, Xun Huang, Arun Mallya, Tero Karras, Timo Aila, Jaakko Lehtinen, and Jan\nKautz. Few-shot unsupervised image-to-image translation. In 2019 IEEE/CVF International\nConference on Computer Vision, ICCV 2019, Seoul, Korea (South), October 27 - November 2,\n2019, pages 10550\u201310559. IEEE, 2019.")))}g.isMDXComponent=!0}}]);